{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = '../../../data/compstat2/train.csv'\n",
    "path_test = '../../../data/compstat2/test.csv'\n",
    "random_state = 2018\n",
    "epochs = 50\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    data = pd.read_csv(\n",
    "        path_train, delimiter=',',\n",
    "        dtype='|U', encoding='utf-8'\n",
    "    ).values\n",
    "    x = data[:, :-1].astype(dtype=float)\n",
    "    y = data[:, -1].astype(dtype=float)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x, y, test_size=0.05, random_state=random_state\n",
    "    )\n",
    "    return (x_train, y_train), (x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred():\n",
    "    data = pd.read_csv(\n",
    "        path_test, delimiter=',',\n",
    "        dtype='|U', encoding=\"utf-8\"\n",
    "    ).values\n",
    "    x_id = data[:, -1]\n",
    "    x = data[:, :-1]\n",
    "    return (x_id.astype(dtype=int), x.astype(dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "    (x_train, y_train), (x_val, y_val) = load_train()\n",
    "    (x_id, x_test) = load_pred()\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_val = x_val.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "\n",
    "    x_train = x_train / 255\n",
    "    x_val = x_val / 255\n",
    "    x_test = x_test / 255\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_val = to_categorical(y_val)\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "    x_val = x_val.reshape(x_val.shape[0], 28, 28, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_val.shape[0], 'validation samples')\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_id, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model():\n",
    "\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "\n",
    "    x = Conv2D(16, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_regularizer='l2',\n",
    "               kernel_initializer='lecun_normal')(inputs)\n",
    "    x = Activation(activation='selu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_regularizer='l2',\n",
    "               kernel_initializer='lecun_normal')(x)\n",
    "    x = Activation(activation='selu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_regularizer='l2',\n",
    "               kernel_initializer='lecun_normal')(x)\n",
    "    x = Activation(activation='selu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3),\n",
    "               padding='same',\n",
    "               kernel_regularizer='l2',\n",
    "               kernel_initializer='lecun_normal')(x)\n",
    "    x = Activation(activation='selu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), kernel_initializer='lecun_normal')(x)\n",
    "    x = Activation(activation='selu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(102)(x)\n",
    "    y = Activation('softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6650, 102)\n",
      "x_train shape: (6650, 28, 28, 1)\n",
      "6650 train samples\n",
      "350 validation samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_id, x_test) = preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 102)               52326     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 102)               0         \n",
      "=================================================================\n",
      "Total params: 493,158\n",
      "Trainable params: 490,758\n",
      "Non-trainable params: 2,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "model.summary()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentations\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.08,\n",
    "    shear_range=0.3,\n",
    "    height_shift_range=0.08,\n",
    "    zoom_range=0.08\n",
    ")\n",
    "val_gen = ImageDataGenerator()\n",
    "train_generator = train_gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_gen.flow(x_val, y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='./Graph', histogram_freq=0,\n",
    "    write_graph=True, write_images=True\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0.0001,\n",
    "    patience=2, verbose=1, mode='auto'\n",
    ")\n",
    "best_model = ModelCheckpoint(\n",
    "    'caltech101.h5', save_best_only=True, verbose=0\n",
    ")\n",
    "plateau = ReduceLROnPlateau(\n",
    "    factor=np.sqrt(0.1), cooldown=0,\n",
    "    patience=5, min_lr=0.5e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "103/103 [==============================] - 16s 153ms/step - loss: 2.2441 - acc: 0.5775 - val_loss: 6.0025 - val_acc: 0.0083\n",
      "Epoch 2/50\n",
      "103/103 [==============================] - 18s 171ms/step - loss: 1.8358 - acc: 0.6372 - val_loss: 6.3371 - val_acc: 0.0099\n",
      "Epoch 3/50\n",
      "103/103 [==============================] - 18s 171ms/step - loss: 1.5859 - acc: 0.6700 - val_loss: 7.4138 - val_acc: 0.0314\n",
      "Epoch 00003: early stopping\n",
      "6650/6650 [==============================] - 3s 442us/step\n",
      "350/350 [==============================] - 0s 445us/step\n",
      "train_results acc:  0.0267669172932\n",
      "val_results adc:    0.0314285714286\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=x_train.shape[0] // 64,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=x_val.shape[0] // 64,\n",
    "    callbacks=[tensorboard, early_stop, best_model, plateau]\n",
    ")\n",
    "train_results = model.evaluate(x_train, y_train)\n",
    "val_results = model.evaluate(x_val, y_val)\n",
    "print('train_results acc: ', train_results[1])\n",
    "print('val_results adc:   ', val_results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = model.predict(x_test)\n",
    "y_ = np.argmax(y_, axis=1)\n",
    "\n",
    "x_id = x_id.reshape(x_id.shape[0], 1)\n",
    "y_ = y_.reshape(y_.shape[0], 1)\n",
    "results = np.concatenate((x_id, y_), axis=1)\n",
    "submission_path = os.path.join(\n",
    "    os.path.dirname(__file__),\n",
    "    'data/submission.csv')\n",
    "np.savetxt(submission_path, results, '%d', delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
